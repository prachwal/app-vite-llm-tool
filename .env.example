# Vector System - Environment Variables Example
# Copy this file to .env.local and fill in your actual values

# AI Embedding Providers
HF_API_KEY=hf_your_huggingface_token_here
OPENAI_API_KEY=sk-your_openai_key_here  
COHERE_API_KEY=your_cohere_key_here

# Database - Netlify Neon Integration
NETLIFY_DATABASE_URL=postgresql://username:password@hostname/database?sslmode=require
NETLIFY_DATABASE_URL_UNPOOLED=postgresql://username:password@hostname/database?sslmode=require

# Vector System Configuration
DEFAULT_EMBEDDING_PROVIDER=huggingface  # Options: huggingface, openai, cohere
VECTOR_CACHE_ENABLED=true               # Enable embedding cache for performance
MAX_CHUNK_SIZE=1000                     # Maximum tokens per text chunk
BATCH_SIZE=10                           # Number of files to process in batch
EMBEDDING_DIMENSIONS=384                # Default for all-MiniLM-L6-v2

# Feature Flags
VECTOR_SYSTEM_ENABLED=true              # Master switch for vector features
BATCH_VECTORIZATION_ENABLED=true       # Enable background batch processing
SEMANTIC_SEARCH_ENABLED=true           # Enable semantic search UI

# Development Settings
LOG_LEVEL=debug                         # Logging level: debug, info, warn, error
ENABLE_PERFORMANCE_METRICS=true        # Track processing times and metrics
